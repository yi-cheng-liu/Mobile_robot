{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NA 568 Mobile Robotics: Methods \\& Algorithms Winter 2021 -- Homework 2 -- Kalman Filtering\n",
    "\n",
    "University of Michigan\\\n",
    "January 25, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5. Estimation (40 points)\n",
    "Assume that we want to estimate an unobserved population parameter $\\theta$ on the basis of observations $x$. Let $f$ be the sampling distribution of $x$ so that $f(x|\\theta)$ is the probability of $x$ when the underlying population parameter is $\\theta$. The function $L(\\theta) = f(x|\\theta)$ when viewed as a function of the parameter $\\theta$ is called the likelihood function or just the likelihood.\n",
    "For example, if $x$ follows a Gaussian distribution, we will have $\\theta = (\\mu, \\sigma^2)$ and $$\\mu, \\sigma \\mapsto f(x|\\mu,\\sigma^2) = \\frac{1}{\\sigma \\sqrt{2\\pi}}\\exp(-\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2})$$ is the likelihood. \n",
    "\n",
    "**Maximum Likelihood Estimator (MLE):** The maximum likelihood method maximizes the likelihood function, leading to the MLE\n",
    "\\begin{equation} \n",
    "    \\nonumber \\hat{\\theta}_{MLE} = \\text{argmax}_\\theta L(\\theta) = \\text{argmax}_\\theta f(x|\\theta).\n",
    "\\end{equation}\n",
    "\n",
    "**Maximum A Posteriori (MAP) Estimator:** In the Bayesian framework, one can place a prior distribution over the parameter, i.e., $g(\\theta)$. Then, the MAP estimator maximizes the posterior probability density function $f(\\theta|x)$ as follows.\n",
    "\\begin{equation}\\nonumber\n",
    "    \\hat{\\theta}_{MAP} = \\text{argmax}_\\theta f(\\theta|x)\n",
    "    = \\text{argmax}_\\theta \\frac{f(x|\\theta)g(\\theta)}{\\int_\\Theta f(x|\\vartheta)g(\\vartheta)d\\vartheta}\n",
    "    = \\text{argmax}_\\theta f(x|\\theta)g(\\theta),\n",
    "\\end{equation}\n",
    "were the last equality is true because the normalization constant in the Bayes' formula is independent of $\\theta$.\n",
    "\n",
    "**Remark:**\n",
    "Since $\\log$ is a monotonic function, it is often the case that we use the logarithm of the likelihood or posterior for maximization (or negative of the logarithm for minimization).\n",
    "\n",
    "\n",
    "Now suppose we have a continuous random variable $\\theta \\sim \\mathcal{N}(\\mu,\\sigma^2)$. We wish to infer its mean and variance as we obtain normally distributed measurements sequentially. For the case of a random mean, $\\mu$, and fixed variance, $\\sigma^2$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. (20 pts) \n",
    "You are responsible for purchasing a sensor that can measure the range (distance) to an object. \n",
    "Sensor I (\\$100) and II (\\$500) are both used to measure the range to an object. \n",
    "Suppose the measurements are noisy values of the range, $x$, such that $z \\sim \\mathcal{N}(\\mu_z,\\sigma_z^2)$ with variances of 1 (I) and 0.64 (II). The measurements obtained from these sensors can be seen in Table I and II. Parameterize the prior of $x$ with $\\mu = 0$ and $\\sigma ^2 = 1000$. Using the derivations from part B, write a Matlab function that takes data as input and solves the inference recursively.\n",
    "C.1 Use the sensor data and the Matlab function to infer the mean and variance of the normally distributed random variable $x$ conditioned only on $z_1$.\n",
    "C.2 Use the sensor data and the Matlab function to infer the mean and variance of the normally distributed random variable $x$ conditioned only on $z_2$.\n",
    "C.3 Why is it that $x$ is more precise~\\footnote{\\href{https://en.wikipedia.org/wiki/Precision\\_(statistics)}{https://en.wikipedia.org/wiki/Precision\\_(statistics)}} when conditioned on $z_1$ even though sensor II is more accurate? which sensor do you recommend to be purchased?\n",
    "\n",
    "Table 1: Sensor I Data\n",
    "    \n",
    "| N   | $Z_1$     |\n",
    "| --- | --------- |\n",
    "| 1   | 10.6715   |\n",
    "| 2   | 8.7925    |\n",
    "| 3   | 10.7172   |\n",
    "| 4   | 11.6302   |\n",
    "| 5   | 10.4889   |\n",
    "| 6   | 11.0347   |\n",
    "| 7   | 10.7269   |\n",
    "| 8   | 9.6966    |\n",
    "| 9   | 10.2939   |\n",
    "| 10  | 9.2127    |\n",
    "\n",
    "Table 2: Sensor II Data\n",
    "    \n",
    "| N   | $Z_2$     |\n",
    "| --- | --------- |\n",
    "| 1   | 10.7107   |\n",
    "| 2   | 9.0823    |\n",
    "| 3   | 9.1449    |\n",
    "| 4   | 9.3524    |\n",
    "| 5   | 10.2602   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor   mean  variance  precision(1/variance)\n",
      "  I     10.325   0.100    10.001\n",
      " II      9.709   0.128     7.813\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# data from sensor I($100 sensor)\n",
    "z1 = [10.6715, 8.7925, 10.7172, 11.6302, 10.4889, 11.0347, 10.7269, 9.6966, 10.2939, 9.2127];\n",
    "\n",
    "# data from sensor II($500 sensor)\n",
    "z2 = [10.7107, 9.0823, 9.1449, 9.3524, 10.2602]\n",
    "\n",
    "# noise variance of sensor I\n",
    "sigma_z1 = 1\n",
    "\n",
    "# noise variance of sensor II\n",
    "sigma_z2 = 0.64\n",
    "\n",
    "# non-informative prior\n",
    "mu_1 = 0\n",
    "sigma_1 = 1000\n",
    "mu_2 = 0\n",
    "sigma_2 = 1000\n",
    "\n",
    "\n",
    "# MAP Bayesian inference using Gaussian prior and likelihood\n",
    "def Inference(mu, sigma, sigma_z, z):\n",
    "#############################################################################\n",
    "#                    TODO: Implement your code here                         #\n",
    "#############################################################################\n",
    "    # Compute the posterior variance\n",
    "    posterior_variance = 1 / (1/sigma + 1/sigma_z)\n",
    "    # Compute the posterior mean\n",
    "    posterior_mean = posterior_variance * (mu/sigma + z/sigma_z)\n",
    "    \n",
    "    mu = posterior_mean\n",
    "    sigma = posterior_variance\n",
    "#############################################################################\n",
    "#                            END OF YOUR CODE                               #\n",
    "#############################################################################\n",
    "    return mu, sigma\n",
    "\n",
    "# recursive inference with data from sensor I and sensor II\n",
    "#############################################################################\n",
    "#                    TODO: Implement your code here                         #\n",
    "#############################################################################\n",
    "# run inferece using z1\n",
    "for i in range(len(z1)):\n",
    "    mu_1, sigma_1 = Inference(mu_1, sigma_1, sigma_z1, z1[i])\n",
    "\n",
    "# run inferece using z2\n",
    "for i in range(len(z2)):\n",
    "    mu_2, sigma_2 = Inference(mu_2, sigma_2, sigma_z2, z2[i])\n",
    "#############################################################################\n",
    "#                            END OF YOUR CODE                               #\n",
    "#############################################################################\n",
    "\n",
    "print(\"sensor   mean  variance  precision(1/variance)\")\n",
    "print(\"  I%11.3f%8.3f%10.3f\" % (mu_1, sigma_1, 1/sigma_1))\n",
    "print(\" II%11.3f%8.3f%10.3f\" % (mu_2, sigma_2, 1/sigma_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. (5 pts)\n",
    "Use a Kalman filter class and write a program to solve C1 and C2. Compare your results with the MAP estimator. What is the conclusion now and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor   mean  variance  precision(1/variance)\n",
      "  I     10.325   0.100    10.001\n",
      " II      9.709   0.128     7.813\n"
     ]
    }
   ],
   "source": [
    "# reset nonâˆ’informative prior\n",
    "mu_1 = 0\n",
    "sigma_1 = 1000\n",
    "mu_2 = 0\n",
    "sigma_2 = 1000\n",
    "\n",
    "# Kalman Filter Measurement Update\n",
    "def KF_update(mu, sigma, sigma_R, z):\n",
    "#############################################################################\n",
    "#                    TODO: Implement your code here                         #\n",
    "#############################################################################    \n",
    "    # prediction\n",
    "    mu_prediction = mu\n",
    "    sigma_prediction = sigma\n",
    "\n",
    "    # innovation\n",
    "    v = z - mu_prediction\n",
    "    s = sigma_prediction + sigma_R # innovation covariance\n",
    "    \n",
    "    # Kalman gain\n",
    "    K_k = sigma_prediction * (1/s)\n",
    "    \n",
    "    # correction step\n",
    "    mu_next = mu_prediction + K_k * v\n",
    "    sigma_next = (1 - K_k) * sigma_prediction * np.transpose(1 - K_k) + K_k * sigma_R * np.transpose(K_k)\n",
    "    \n",
    "    return mu_next, sigma_next\n",
    "\n",
    "#############################################################################\n",
    "#                            END OF YOUR CODE                               #\n",
    "#############################################################################\n",
    "\n",
    "# recursive inference with data from sensor I and sensor II\n",
    "#############################################################################\n",
    "#                    TODO: Implement your code here                         #\n",
    "#############################################################################\n",
    "# run inferece using z1\n",
    "for i in range(len(z1)):\n",
    "    mu_1, sigma_1 = KF_update(mu_1, sigma_1, sigma_z1, z1[i])\n",
    "\n",
    "# run inferece using z2\n",
    "for i in range(len(z2)):\n",
    "    mu_2, sigma_2 = KF_update(mu_2, sigma_2, sigma_z2, z2[i])\n",
    "\n",
    "#############################################################################\n",
    "#                            END OF YOUR CODE                               #\n",
    "#############################################################################\n",
    "\n",
    "print(\"sensor   mean  variance  precision(1/variance)\")\n",
    "print(\"  I%11.3f%8.3f%10.3f\" % (mu_1, sigma_1, 1/sigma_1))\n",
    "print(\" II%11.3f%8.3f%10.3f\" % (mu_2, sigma_2, 1/sigma_2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (v3.10.7:6cc6b13308, Sep  5 2022, 14:02:52) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
